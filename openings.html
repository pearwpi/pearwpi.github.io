	<!DOCTYPE html>
	<html lang="zxx" class="no-js">
	<head>
		<!-- Mobile Specific Meta -->
		<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
		<!-- Favicon-->
		<link rel="shortcut icon" href="img/fav.png">
		<!-- Author Meta -->
		<meta name="author" content="colorlib">
		<!-- Meta Description -->
		<meta name="description" content="">
		<!-- Meta Keyword -->
		<meta name="keywords" content="">
		<!-- meta character set -->
		<meta charset="UTF-8">
		<!-- Site Title -->
		<title>PeAR WPI</title>
		<!-- Site Title -->

		<link href="https://fonts.googleapis.com/css?family=Poppins:100,200,400,300,500,600,700" rel="stylesheet"> 
			<!--
			CSS
			============================================= -->
			<link rel="stylesheet" href="css/linearicons.css">
			<link rel="stylesheet" href="css/font-awesome.min.css">
			<link rel="stylesheet" href="css/bootstrap.css">
			<link rel="stylesheet" href="css/magnific-popup.css">			
			<link rel="stylesheet" href="css/nice-select.css">							
			<link rel="stylesheet" href="css/animate.min.css">
			<link rel="stylesheet" href="css/owl.carousel.css">			
			<link rel="stylesheet" href="css/jquery-ui.css">			
			<link rel="stylesheet" href="css/main.css">
            <!-- Global site tag (gtag.js) - Google Analytics -->
            <script async src="https://www.googletagmanager.com/gtag/js?id=UA-171009851-1"></script>
            <script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments);}
              gtag('js', new Date());

              gtag('config', 'UA-171009851-1');
            </script>
		</head>
		<body>	
        <!-- EDIT ME -->
        	<header id="header">
        	<div class="container main-menu">
        	    <div class="row align-items-center justify-content-between d-flex"> 
        	      <!--  style="margin-left: -36vh; margin-right: -36vh" -->
        	      <div id="logo">
        	        <a href="index.html" style="font-size: 24px; font-weight: 800"><img src="img/logos/LogoWhiteRed.png" width="48px" alt="" title=""> Perception and Autonomous Robotics Group</a>
        	      </div>
        	      <nav id="nav-menu-container">
        	        <ul class="nav-menu">
        	          <li><a title="Home" href="index.html" style="position: relative; top: -4px"><i style="font-size: 28px" class="fa fa-home"></i></a></li>
        	          <li class="menu-has-children"><a title="Research" href="research.html">Research</a>
        	            <ul>
        	              <li><a href="research.html">Research Areas</a></li>
        	              <!-- <li><a href="softwares.html">Softwares/Datasets</a></li> -->
        	              <li><a href="publications.html">Publications/Softwares/Datasets</a></li>
        	              <li><a href="labs.html">Research Labs And Facilities</a></li>
        	            </ul>
        	          </li> 
        	          <li><a title="Teaching" href="teaching.html">Teaching</a></li>
        	         <li><a title="Media" href="media.html">Media</a></li>
        	         <li><a title="Openings" href="openings.html">Openings</a></li>
        	         <li><a title="Events" href="events.html">Events</a></li>
        	          </ul>
        	        </nav><!-- #nav-menu-container -->                  
        	    </div>
        	</div>
        	</header>          	<!-- EDIT ME -->

          <!-- Start home-about Area -->
			<section class="sample-text-area">
				<div class="container">
					<div class="menu-content">
                    <div class="title text-center">
                        <h1 class="mb-10">Openings</h1>
                    </div>
                </div>
				</div>
			</section>

		  <section class="sample-text-area", style="padding-top: 10px">
				<div class="whole-wrap">
				<div class="container">
					<br><br>
					<h4>We are hiring multiple talented Ph.D. students, Masters students for Directed Research/Thesis and Undergraduates for MQPs in the field of aerial robotics and Computer Vision/Robot Perception.</h4>
					<hr>
					<h4><b><p style="color: var(--themecolor)">Come push the boundaries of what is possible on tiny robots with us!</p></b></h4>

					Our mission is to tackle fundamental problems in robot perception and autonomy to enable better life. We work on pushing the boundaries of autonomy at extreme resource constrained tiny robots using only on-board computation and sensing. In-particular we work on navigation of nano-drones (and other robots) using only cameras and inertial sensors and onboard computation without the need for external infrastructure such as GPS or motion capture systems. We call our approach to autonomy as Minimal-AI due to the nature of its design and its efficiency in solving the desired tasks. We utilize concepts from Active Perception, Interactive Perception, Passive and Novel computing and Deep Compression. <a href="index.html">Our current members</a> include Ph.D. students, Masters students and undergraduate students across various nationalities and ages. We actively seek funding, collaboration and new research areas with the common theme mentioned above. We work on pushing the boundaries of what is possible today's robot autonomy with realistic constraints.  <br><br>

					We are currently hiring in four domains:<br>
					<ul class="unordered-list">
						<li> <a href="#highspeed">High-speed autonomous flight through cluttered environments</a> </li>
						<li> <a href="#sensorfusion">Robust light-weight sensor fusion using deep learning</a> </li>
						<li> <a href="#morph">Morphable aerial robot navigation through tight spaces</a> </li>
						<li> <a href="#novelsense">Novel Sensing Using Passive Computation</a> </li><br><br>
					</ul>

					Some FAQs are given below:
					<ul class="unordered-list">
						<li> <a href="#whyus">Why work with us?</a> </li>
						<li> <a href="#whoarewe">Who are we?</a> </li>
						<li> <a href="#skills">What are the necessary skills to join PeAR?</a> </li>
						<li> <a href="#expectations">What are the work expectations?</a> </li>
						<li> <a href="#deadlines">What are the deadlines/starting dates?</a> </li>
						<li> <a href="#apply">How do I apply?</a> </li>
						<li> <a href="#contact"><b><span style="color: var(--themecolor);">IMPORTANT: How do I contact you?</b></span></a> </li>
					</ul>

					<hr>

					<a name='highspeed'></a>
					<h3>High-speed autonomous flight through cluttered environments</h3><br>
					<!-- <video src="img/openings/MorphEyes.mp4" autoplay muted loop style="width: 30vh; border-radius: 16px"> -->
						<video src="img/openings/MorphEyes.mp4" autoplay muted loop style="width: 70vh; border-radius: 16px"> </video><br><br>

							Autonomous flight has been achieved in low-speed scenarios with a suite of sensors such as cameras, inertial sensors and LIDARs. There are even products like the Skydio drone or the DJI Drones that can do this today. However, finding safe regions to fly fast to in a cluttered scene is still an open challenge. The question becomes even harder, when we limit the size and thereby the computation and sensory capabilities of the robots to the size of a hummingbird. <br><br>

							The goal of the Ph.D. research/Masters research is to explore various strategies in visual representation, neural compression and reinforcement learning to push robot autonomy at nano-quadrotor scales (<120mm size and <200g weight) to achieve 30m/s flight in cluttered environments such as forests.    <br><br>

							Read about our research in this area given below (please check out the papers in the following links):
							<ul class="unordered-list">
							<li> <a href="visionbasedquad.html">Vision-Based Quadrotor Flight</a> </li>
							<li> <a href="sim2real.html">Sim2Real And Real2Sim</a> </li>
						  </ul>
						  <hr>
						  <br><br>

				  <a name='sensorfusion'></a>
				  <h3>Robust light-weight sensor fusion using deep learning</h3><br>
				  <img src="img/research/PRGFlow.png" style="width: 70vh; border-radius: 16px" alt="" class="img-fluid"><br><br>

				  Autonomous navigation often involves estimation of egomotion/odometry to take the next control action. However, sensors are often noisy and hence directly using any single sensor for estimation of egomotion is not desired. To this end, roboticists use a plethora of sensors on robots and exploit the complementary nature of their noises to obtain a better estimate. This is often achieved Bayesian filters such as a Kalman filter. Despite this massive success, it becomes hard to tune the parameters and often the accuracy is limited by the resolution of calibration. To this end, we propose to utilize deep learning to enable better sensor fusion followed by network quantization for deployment on tiny robots.  <br><br>  

				  The goal of the Ph.D. research/Masters research is to explore various strategies in multi-sensor fusion for autonomy using cameras (event-based and classical), inertial sensors and acoustic sensors to push robot autonomy at nano-quadrotor scales (<120mm size and <200g weight) to achieve flight in cluttered environments such as forests.    <br><br>   

				  Read about our research in this area given below (please check out the papers in the following links):
				 <ul class="unordered-list">
					<li> <a href="visionbasedquad.html">Vision-Based Quadrotor Flight</a> </li>
					<li> <a href="sim2real.html">Sim2Real And Real2Sim</a> </li>
					<li> <a href="eventvision.html">Neuromorphic Event-based Sensing and Computing</a> </li>
				  </ul>
				  <hr>
				  <br><br>

				  <a name='morph'></a>
				  <h3>Morphable aerial robot navigation through tight spaces</h3><br>
				  <img src="img/openings/morphingquad.png" style="width: 70vh; border-radius: 16px" alt="" class="img-fluid"><br><br>

				  Birds possess a remarkable combination of morphing abilities that enable them to navigate through narrow spaces with astonishing agility. One key aspect is their capacity to fold their wings tightly against their bodies, reducing their wingspan and allowing them to effortlessly maneuver through tight gaps and intricate environments. This folding ability, combined with their adept walking skills, grants birds unparalleled adaptability. By utilizing their wings as additional limbs, birds can maintain balance and stability while navigating narrow surfaces. This unique blend of folding wings and walking proficiency empowers birds to explore and exploit even the most challenging aerial and terrestrial landscapes, showcasing their remarkable versatility and mastery of movement.  <br><br> 

				  The goal of the Ph.D. research/Masters research is to explore various strategies for design of morphing strategies based on percpetion and morphology agonistic minimal visual scene representations for navigation in cluttered environments such as forests/air conditioning ducts.   <hr>
				  <br><br>


				  <a name='novelsense'></a>
				  <h3>Novel Sensing Using Passive Computation</h3><br>
				  <img src="img/research/passivecomp.png" style="width: 70vh; border-radius: 16px" alt="" class="img-fluid"><br><br>

				  In the intricate tapestry of the natural world, animals have evolved fascinating strategies to perceive and comprehend the three-dimensional scenes that unfold before them. One remarkable adaptation lies in their eyes and acoustic senses, which have embraced asymmetry to decode spatial structures. Many animals possess eyes positioned on opposite sides of their heads, allowing for a wider field of view and depth perception. This disparity in visual input helps them gauge the distance and orientation of objects, enabling them to navigate complex environments with precision. Additionally, certain species have developed specialized auditory systems that leverage sound localization to map their surroundings. By discerning minute differences in the arrival time and intensity of sounds, these creatures can construct a mental map of their 3D environment. Through the evolution of asymmetrical sensory mechanisms, animals have unlocked the ability to perceive and interpret the multidimensional world they inhabit, showcasing nature's ingenuity and adaptability. <br><br> 

				  When building tiny autonomous robots, one needs to re-imagine the sensor suite and go back to the drawing board to propose novel ways to receive sensor information and process them. We work on the physical modelling using mathematical tools from computational imaging to push the boundaries of what is possible with minimal amount of sensing and perception. <br><br> 

				  The goal of the Ph.D. research/Masters research is to explore various strategies for crafting such structures driven through modelling and simulation. We aim to explore reinforcement learning to explore sensory design for pushing sensing capabilities at tiny scales using coded apertures and coded lenses for navigation.<hr>
				  <br><br>

				  <a name='whyus'></a>
					<h3>Why work with us?</h3><br>
					<ul class="unordered-list">
					<li> We do cutting-edge and world-class research and our work has won many awards and has attracted a lot of media attention. More information can be found <a href="media.html">here</a>. </li>
					<li> Whatever career path you desire, be it industry or academia or setting up your own startup, working at PeAR will enable you to achieve your dreams. Prof. Sanket dedicates a lot of time talking to his students and mentoring them to aid in brining out the best in his students. PeAR students work at the best places currently such as Tesla, Google, Waymo, SkyDio to name a few.  </li>
					<li>  Our work has been often featured in wold news and mass media such as BBC, Voice of America, IEEE Spectrum to name a few. Find more infromation <a href="media.html">here</a>. </li>
				  <li>  Our Ph.D. positions are fully-funded. </li>
				  <li>  Ph.D. and postdoc positions have <b>employee benefits</b> such as health insurance and access to the gym. </li>
				  <li>  You will recieve a very competitive salary and access to outstanding research facilities such as motion capture, 3D printing, large flying spaces, electronic and machine shops. More information about our lab space can be found <a href="labs.html">here</a>. </li>
				  <li>  Outstanding work atmosphere with many social events such as lab dinners and home-cooked meals from Prof. Sanket's kitchen (promised to be better than any Indian restaurant around). </li>
				  <li>  Sponsored travel to other countries for published conference papers. </li>
				  <li>  Talks and visits by internationally renowned researchers from labs and companies. </li>
				  <li>  Extensive collaborations with top researchers across the world. </li>
				  <li>  <a href="https://masstech.org/robotics">Massachussets is one of the largest hubs</a> for robotics in the world with being home to 345 companies and over USD 1B investements for research. </li>
				  <li>  Massachussets is one of the best places in the world to start your own company, join an industry or become an academic due to the sheer number of opportunities. </li>
				  <li>  WPI is consistently ranked in the <a href="https://www.collegefactual.com/colleges/worcester-polytechnic-institute/academic-life/academic-majors/engineering/robotics-engineering/#:~:text=WPI%20Robotics%20Engineering%20Rankings,in%20this%20field%20of%20study.">top 5 robotics schools in the country</a>. </li>
				  </ul>
				  <hr>
				  <br><br>


				  <a name='whoarewe'></a>
					<h3>Who are we?</h3><br>
					The Perception and Robotics Group abbreviated as PeAR is hosted in the <a href="https://www.wpi.edu/academics/departments/robotics-engineering">Robotics Engineering department</a> at <a href="https://www.wpi.edu/">Worcester Polytechnic Institute</a> (WPI). We also have affiliations to the <a href="https://www.wpi.edu/academics/departments/computer-science">Department of Computer Science</a> and the <a href="https://www.wpi.edu/academics/departments/electrical-computer-engineering">Department of Electrical and Computer Engineering</a> at WPI. <br><br>

					We work extensively on fundamental problems in robot perception and autonomy to enable better life. Our work mostly consists of making tiny autonomous aerial robots using only onboard computation and sensing.<br><br>

					Our former students are in some of the top companies in the world such as Tesla, Google, Waymo to name a few. More information can be found <a href="alumni.html">here</a>.<br><br>

					The research carried out in our lab has recieved extensive media coverage. Please find the information <a href="media.html">here</a>.<br><br>

					An up to date list of all our research projects can be found <a href="research.html">here</a> and all our publication list can be found <a href="publications.html">here</a>.
				  <hr>
				  <br><br>

				  <a name='skills'></a>
					<h3>What are the necessary skills to join PeAR?</h3><br>
					<ul class="unordered-list">
					<li> For <b>Ph.D. applications</b>, a Masters degree in robotics, aerospace engineering, computer science, electrical and computer engineering, physics, aerodynamics, or related fields. If you do not have a Masters degree, a strong requirement on prior knowledge or experience in the field of aerial robotics or computer vision is required.</li>
					<li> For <b>Masters thesis/research applications</b>, an undergraduate degree in robotics, aerospace engineering, computer science, electrical and computer engineering, physics, aerodynamics, or related fields is a must. Furthermore, the student <b>MUST HAVE</b> taken one of the <a href="teaching.html">graduate courses Prof. Sanket offers</a>.</li>
					<li> For <b>Undergraduate thesis/MQP applications</b>, the student should be enrolled in an undergraduate program in one of the following fields: robotics, aerospace engineering, computer science, electrical and computer engineering, physics, aerodynamics, or related fields. Furthermore, the student <b>MUST HAVE</b> taken one of the <a href="teaching.html">undergraduate courses Prof. Sanket offers</a> or a course in computer vision or AI and must have excellent programming skills.</li>
				  <li> A strong passion for robotics, computer vision, mathematics, programming and abstract thinking. </li>
				  <li> Excellent written and spoken English skills. </li>
				  <li> Very strong Python, C++ or Matlab skills. </li>
				  <li> Strong prior experience in robotics or computer vision is required. </li>
				  <li> Strong background knowledge any of the following areas: robot perception/computer vision, neural networks, controls, path planning, state estimation, sensor fusion, numerical optimization. </li>
				  <li> Hands-on experience with CAD, ROS, TensorFlow, PyTorch, OpenCV and GitHub is highly desirable. </li>
				  </ul>
				  <hr>
				  <br><br>

				  <a name='expectations'></a>
					<h3>What are the work expectations?</h3><br>
					We expect the student to be passionate about the field and work towards a goal. Work at PeAR is fast-paced and exciting with needing to learn new tools and concepts quickly. You are expected to seek for help when needed but grow as an independent researcher with critical thinking and self-reflection. Robotics experiments do take up a significant amount of time with crashes being common when pushing the boundaries of the field. Watch <a href="https://www.youtube.com/watch?v=haZG_Xs5LOM&feature=youtu.be">this video</a> for a feel of how it is to work with us. We assure you that you'll learn a lot, grow as an individual and as a team and take with you a family for life. Most of all, you'll make fun memories that will last you a lifetime.  
				  <hr>
				  <br><br>

				  <a name='deadlines'></a>
					<h3>What are the deadlines/starting dates?</h3><br>
					<b>For Ph.D. applications, the starting date will be in the upcoming next-year's Fall semester (for e.g., if you are applying in June 2023, your position will start in Fall 2024). For Masters and undergraduate applications, we hire new students every semester (Fall and Spring). These positions will be open until filled. Please check this page for current open positions.</b>
				  <hr>
				  <br><br>

				  <a name='apply'></a>
					<h3>How do I apply?</h3><br>
					For Ph.D. applications follow the steps described <a href="phd.html">here</a>.<br><br>

					For Masters thesis/directed research/independent study applications follow the steps described <a href="masters.html">here</a>. <b><span style="color: var(--themecolor); font-weight: 800;">These positions are ONLY for current WPI students.</span></b><br><br>

					For undergraduate research/MQP follow the steps described <a href="undergraduate.html">here</a>. <b><span style="color: var(--themecolor); font-weight: 800;">These positions are ONLY for current WPI students.</span></b><br><br>

					<b><span style="color: var(--themecolor); font-weight: 800;">IMPORTANT: Recommendation letters are not required at the first stage but if you have them already, feel free to upload them in the application form. In case you are selected for an online/in-person interview and you hear a positive response, recommendation letters will be requested when you apply through the application portal (for Ph.D. applications) and through email (for Masters and Undergraduate applications).</span></b>
				  <hr>
				  <br><br>

				  <a name='contact'></a>
					<h3><span style="color: var(--themecolor);">IMPORTANT: How do I contact you?</span></h3><br>
					For questions, please contact Prof. Nitin J. Sanket using the <a href="https://mailhide.io/e/7anJau8i">following email</a> (please do not use his private email for inquiries about the openings). <b><span style="color: var(--themecolor); font-weight: 800;">Please do not send inquiries asking to check whether your CV fits any of the positions. If you are unsure, just apply; you have nothing to lose. Applications sent directly by email and not through the web form will not be considered. In case of positive feedback, you will be contacted. If not positive, you won't hear back.</span></b>
				  <hr>
				  <br><br>

				</div>
			</div>
			</section>

		  
            <!-- EDIT FOOT -->
            	<!-- start footer Area -->
            	            <section class="facts-area section-gap" id="facts-area"  style="background-color: rgba(255, 255, 255, 1.0); padding: 40px">
            	                <div class="container">     
            	                <div class="title text-center">
            	                        <p> <a href="index.html"><img src="img/logos/LogoBlackRed.png" width="128px" alt="" title=""></a><br><br>
            	                            Perception and Autonomous Robotics Group <br>
            	                            Worcester Polytechnic Institute <br>
            	                            Copyright © 2023<br>
            	                            <span style="font-size: 10px">Website based on <a href="https://colorlib.com" target="_blank">Colorlib</a></span>
            	                        </p>
            	                    </div>
            	                </div>  
            	            </section>  
            	<!-- End footer Area -->            	<!-- End footer Area -->            <!-- EDIT FOOT -->	

			<script src="js/vendor/jquery-2.2.4.min.js"></script>
			<script src="js/popper.min.js"></script>
			<script src="js/vendor/bootstrap.min.js"></script>			
			<script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyBhOdIF3Y9382fqJYt5I_sswSrEw5eihAA"></script>			
  			<script src="js/easing.min.js"></script>			
			<script src="js/hoverIntent.js"></script>
			<script src="js/superfish.min.js"></script>	
			<script src="js/jquery.ajaxchimp.min.js"></script>
			<script src="js/jquery.magnific-popup.min.js"></script>	
    		<script src="js/jquery.tabs.min.js"></script>						
			<script src="js/jquery.nice-select.min.js"></script>	
            <script src="js/isotope.pkgd.min.js"></script>			
			<script src="js/waypoints.min.js"></script>
			<script src="js/jquery.counterup.min.js"></script>
			<script src="js/simple-skillbar.js"></script>							
			<script src="js/owl.carousel.min.js"></script>							
			<script src="js/mail-script.js"></script>	
			<script src="js/main.js"></script>	
		</body>
	</html>